# ML Pipeline Structure Overview

## ğŸ“ File Organization

```
end_2_end_ml_with_observability_mljobs/
â”œâ”€â”€ ğŸš€ main_pipeline.py           # Main orchestrator (ENTRY POINT)
â”œâ”€â”€ âš™ï¸  config.py                  # Configuration and constants
â”œâ”€â”€ ğŸ› ï¸  utils.py                   # Common utility functions
â”œâ”€â”€ ğŸ“¥ data_ingestion.py          # Data loading and processing
â”œâ”€â”€ ğŸ”§ feature_engineering.py    # Feature creation and management
â”œâ”€â”€ ğŸ·ï¸  labeling.py               # Churn label generation
â”œâ”€â”€ ğŸ¤– model_training.py         # ML model training and evaluation
â”œâ”€â”€ ğŸ“Š model_monitoring.py       # Model monitoring and inference
â”œâ”€â”€ ğŸ“‹ requirements.txt          # Python dependencies
â”œâ”€â”€ ğŸ® run_pipeline.py           # Convenience runner script
â”œâ”€â”€ ğŸ§ª test_imports.py           # Module import validator
â”œâ”€â”€ ğŸ“– README.md                 # Complete documentation
â”œâ”€â”€ ğŸ“ PIPELINE_STRUCTURE.md     # This file
â””â”€â”€ ğŸ““ E2E_ML_WORKFLOW_sklearn_f1.ipynb  # Original notebook
```

## ğŸ”„ Execution Flow

### 1. Initialization Phase
```
main_pipeline.py â†’ config.py â†’ utils.py â†’ data_ingestion.py
                                      â†“
                              Create schemas, tables, staging areas
                                      â†“
                              Discover and register data files
                                      â†“
                              Load static customer data
```

### 2. Training Phase
```
feature_engineering.py â†’ Create behavioral features
         â†“
labeling.py â†’ Generate churn labels
         â†“
model_training.py â†’ Train and register XGBoost model
         â†“
model_monitoring.py â†’ Setup monitoring infrastructure
```

### 3. Continuous Learning Phase
```
data_ingestion.py â†’ Load new monthly data
         â†“
feature_engineering.py â†’ Create features for new data
         â†“
labeling.py â†’ Update labels with new transactions
         â†“
model_monitoring.py â†’ Run inference and performance checks
         â†“
model_training.py â†’ Retrain if performance drops
         â†“
model_monitoring.py â†’ Update production model
```

## ğŸ§© Module Dependencies

### Core Dependencies
- `config.py` â† All modules (provides configuration)
- `utils.py` â† All modules (provides utilities)

### Data Flow Dependencies
```
data_ingestion.py â†’ feature_engineering.py â†’ labeling.py
                                     â†“
                              model_training.py
                                     â†“
                              model_monitoring.py
```

### Import Structure
```python
# All modules import from:
from config import config, logger
from utils import [specific utilities]

# Specific dependencies:
data_ingestion.py â†’ utils (FileUtils, DatabaseUtils)
feature_engineering.py â†’ utils (ValidationUtils, FeatureStoreUtils)
labeling.py â†’ utils (ValidationUtils)
model_training.py â†’ utils (ModelUtils, DateUtils)
model_monitoring.py â†’ utils (ModelUtils, DateUtils)
```

## ğŸ¯ Key Classes and Functions

### Main Orchestrator (`main_pipeline.py`)
- `MLPipelineOrchestrator`: Complete pipeline management
  - `run_initialization()`: Setup environment
  - `run_initial_training()`: Train baseline model
  - `run_continuous_learning()`: Continuous learning loop
  - `run_drift_simulation()`: Data drift testing

### Data Processing (`data_ingestion.py`)
- `DataIngestionPipeline`: Main data loading orchestrator
- `DataQualityChecker`: Data validation and quality metrics

### Feature Engineering (`feature_engineering.py`)
- `FeatureEngineer`: Creates customer behavioral features
- `FeatureValidator`: Validates feature quality and drift
- `FeatureStoreManager`: Manages Feature Store operations

### Labeling (`labeling.py`)
- `ChurnLabeler`: Creates churn labels based on future behavior
- `LabelQualityChecker`: Validates label consistency

### Model Training (`model_training.py`)
- `ModelTrainer`: XGBoost training and evaluation
- `ModelValidator`: Performance validation
- `ModelComparator`: Model comparison and selection

### Monitoring (`model_monitoring.py`)
- `ModelMonitor`: Inference and monitoring setup
- `PerformanceTracker`: Performance tracking over time
- `DriftDetector`: Feature and prediction drift detection
- `AlertManager`: Alert generation and management

## ğŸ”§ Configuration System

### Environment Variables
```bash
ML_SCHEMA=E2E_DEMO              # Working schema
ML_WAREHOUSE=COMPUTE_WH         # Compute warehouse
CHURN_WINDOW=30                 # Days to define churn
RETRAIN_THRESHOLD=0.8           # F1 threshold for retraining
```

### Config Classes
- `Config`: Main configuration class with validation
- `FeatureConfig`: Feature engineering specific settings

## ğŸš€ Usage Patterns

### Quick Start
```bash
# Initialize environment only
python main_pipeline.py --mode init

# Train baseline model
python main_pipeline.py --mode train --months 4

# Run complete pipeline
python main_pipeline.py --mode continuous --months 4

# Using convenience script
python run_pipeline.py quick-demo
```

### Advanced Usage
```python
from main_pipeline import MLPipelineOrchestrator

# Programmatic usage
pipeline = MLPipelineOrchestrator()
pipeline.run_initialization()
baseline_model, metrics = pipeline.run_initial_training(num_months=6)
iterations = pipeline.run_continuous_learning(max_iterations=10)
```

## ğŸ“Š Data Flow

### Input Data
```
S3 Bucket â†’ CSV Files â†’ Snowflake Staging â†’ Core Tables
    â†“
sales_YYYY_MM.csv â†’ SALES table
feedback_raw_YYYY_MM.csv â†’ FEEDBACK_RAW table
customers.csv â†’ CUSTOMERS table
```

### Feature Pipeline
```
SALES + CUSTOMERS + FEEDBACK_SENTIMENT
    â†“
Time-series aggregations + Customer profiling
    â†“
CUSTOMER_FEATURES table
    â†“
Churn labeling logic
    â†“
CUSTOMER_FEATURES_LABELED table
    â†“
Feature Store integration
    â†“
Training/Validation datasets
```

### Model Pipeline
```
Training Dataset â†’ XGBoost Pipeline â†’ Model Registry
    â†“
Validation Dataset â†’ Performance Metrics
    â†“
Production Inference â†’ Monitoring Tables
    â†“
Performance Tracking â†’ Retraining Triggers
```

## ğŸ” Monitoring & Observability

### Performance Metrics
- F1 Score (primary metric)
- Precision, Recall, Accuracy
- Training vs Test performance gaps

### Drift Detection
- Feature distribution changes
- Prediction distribution shifts
- Label distribution evolution

### Quality Checks
- Data completeness and consistency
- Feature validation and correlation
- Label quality and temporal consistency

## ğŸ›ï¸ Customization Points

### Easy Customizations
- Change churn window: Modify `CHURN_WINDOW` in config
- Adjust retraining threshold: Change `RETRAIN_THRESHOLD`
- Add new features: Extend `NUMERICAL_COLS` or `CATEGORICAL_COLS`
- Modify model: Replace XGBoost in `ModelTrainer`

### Advanced Customizations
- New data sources: Extend `DataIngestionPipeline`
- Custom features: Add methods to `FeatureEngineer`
- Different algorithms: Create new trainer classes
- Custom monitoring: Extend `ModelMonitor` and `DriftDetector`

## ğŸš¨ Error Handling

### Built-in Safeguards
- Data validation at each step
- Configuration validation on startup
- Graceful handling of missing data
- Automatic rollback on training failures

### Logging & Debugging
- Comprehensive logging at all levels
- Performance timing for each operation
- Error context and stack traces
- Progress indicators for long operations

---

**This structure provides a complete, production-ready ML pipeline that's easy to understand, modify, and deploy in CI/CD environments.**
